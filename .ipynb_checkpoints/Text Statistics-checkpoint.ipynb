{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Statistics using Python and Regular Expressions\n",
    "\n",
    "### Introduction\n",
    "\n",
    "The goal of this project is to show relevant statistics of a text file similar to the Word Count box from Microsoft Word.\n",
    "\n",
    "![](figures/TextStatisticsFromMSWord_Small.png)\n",
    "\n",
    "Notepad++ also provides the total number of characters and lines for each file at the bottom portion of the application.\n",
    "![](figures/TextStatisticsFromNotepadPlusPlus.png)\n",
    "\n",
    "This project will also display the top 10 most frequently occuring word from the file.\n",
    "\n",
    "Results show that the computed text statistics values closely match that of the values from Microsoft Word and Notepad++. The top most frequently occuring words coming from a compilation of all Shakespeare literature corresponds to the most commonly used words in English.\n",
    "\n",
    "The experience from this endeavor will be used in creating an email spam filter model, which depends heavily on features extracted from sample email texts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### String Manipulation\n",
    "\n",
    "The next cells will show how common Python functions (e.g., __len__, __print__, __split__, __lower__, and __set__) can be used in this project. The sample text will be taken from Tolkien's The Hobbit novel.  \n",
    "\n",
    "\"In a hole in the ground there lived a hobbit. Not a nasty, dirty, wet hole, filled with the ends of worms and an oozy smell, nor yet a dry, bare, sandy hole with nothing in it to sit down on or to eat: it was a hobbit-hole, and that means comfort.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = \"In a hole in the ground there lived a hobbit.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of characters:  45\n"
     ]
    }
   ],
   "source": [
    "# total characters\n",
    "numChars = len(text)\n",
    "print(\"Total number of characters: \", numChars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words:  10\n",
      "Words:  ['In', 'a', 'hole', 'in', 'the', 'ground', 'there', 'lived', 'a', 'hobbit.']\n"
     ]
    }
   ],
   "source": [
    "# Split and total number of words after split\n",
    "splitWords = text.split()\n",
    "numWords = len(splitWords)\n",
    "print(\"Total number of words: \", numWords)\n",
    "print(\"Words: \", splitWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several observations that can be made from this naive implementation to get words from the text.\n",
    "\n",
    "The 10th word is \"hobbit.\", with a period at the end of the word. This will cause issues later if another word \"hobbit\" is encountered. The code may consider it to be different words, even if the difference was due to a punctuation mark at the end of the sentence. \n",
    "\n",
    "The first word \"In\" may also be considered distinct to the fourth word \"in\" if preprocessing is not performed on the raw text.\n",
    "\n",
    "The first preprocessing that can be done is to convert everything to lowercase using the __lower__ function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in', 'a', 'hole', 'in', 'the', 'ground', 'there', 'lived', 'a', 'hobbit.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to lowercase\n",
    "splitWords = text.lower().split()\n",
    "splitWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a', 'ground', 'hobbit.', 'hole', 'in', 'lived', 'the', 'there'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get unique words\n",
    "distinctWords = set(text.lower().split())\n",
    "distinctWords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that there is only a single instance of the word \"in\". \n",
    "\n",
    "However, the string \"hobbit.\" is still currently considered as a distinct word. We need to take note of the characters that need to be retained in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# retain these characters (store them in a set)\n",
    "retainChars = {'a','b','c','d','e','f','g','h','i','j',\n",
    "               'k','l','m','n','o','p','q','r','s','t',\n",
    "               'u','v','w','x','y','z',' ','-',\"'\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The apostrophe is retained to handle word contractions such \"We'd\", which stands for \"We had\" or \"We would\". Removing the apostrophe will transform \"We'd\" to \"Wed\", which is also a valid word. \n",
    "\n",
    "The __normalize__ function below will combine the two operations of converting the characters to lowercase and only retaining characters specified in the set, retainChars. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(s):\n",
    "    \"\"\"Convert string to lowercase and keep only characters \n",
    "        specified in retainChars\"\"\"\n",
    "    return ''.join(char for char in s.lower() if char in retainChars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized text:  in a hole in the ground there lived a hobbit\n",
      "Distinct words:  {'hobbit', 'there', 'lived', 'a', 'ground', 'the', 'hole', 'in'}\n"
     ]
    }
   ],
   "source": [
    "normalizedText = normalize(text)\n",
    "distinctWords = set(normalizedText.split())\n",
    "print(\"Normalized text: \", normalizedText)\n",
    "print(\"Distinct words: \", distinctWords)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the word hobbit does not contain the period anymore after passing the raw text to the __normalize__ function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Regular Expressions\n",
    "\n",
    "The __normalize__ function can be rewritten to use the concept of regular expressions (regex) to retain only the characters specified in *retainChars*. The equivalent regex pattern for *retainChars* is __r'[a-z\\s\\'-]'__.\n",
    "\n",
    "Substituting all characters that do not belong to the *retainChars* set with empty string values will also achieve the same effect as creating a new string variable and retaining only the characters in the *retainChars* set.\n",
    "\n",
    "To achieve this scenario, we will be using the __re.sub__ function with a pattern of __r'[^a-z\\s\\'-]'__. The __^__ symbol means  negation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized text:  in a hole in the ground there lived a middle-aged hobbit i'd like to live there\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "text = \"In a hole in the ground there lived a middle-aged hobbit. I'd like to live there.\"\n",
    "normalizedText = re.sub(r'[^a-z\\s\\'-]','',text.lower())\n",
    "print(\"Normalized text: \", normalizedText)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regular expression of the __normalize__ function is shown below. Note that before the input text string is converted to all lowercase, the leading and trailing spaces are trimmed using the __strip__ function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"in a hole in the ground there lived a middle-aged hobbit i'd like to live there\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def normalizeRegEx(s):\n",
    "    \"\"\"Convert string to lowercase and keep only characters \n",
    "        specified in regex pattern\"\"\"\n",
    "    return re.sub(r'[^a-z\\s\\'-]','',s.strip().lower())\n",
    "\n",
    "text = \"In a hole in the ground there lived a middle-aged hobbit. I'd like to live there.\"\n",
    "normalizedText = normalizeRegEx(text)\n",
    "normalizedText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Basic Text Statistics\n",
    "\n",
    "We are interested to find the following information from the text file: (a) number of words, (b) characters (with spaces), (c) characters (no spaces), and (d) lines.\n",
    "\n",
    "The following code snippet can extract these pieces of information.\n",
    "\n",
    "For the number of lines, we follow the assumption that if the file is empty, the number of lines is considered to be zero. However, if the there is at least single character in the file, even if there is no newline character (__\\n__), the number of lines is considered to be one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words:  16\n",
      "Number of characters (with spaces):  81\n",
      "Inaholeinthegroundtherelivedamiddle-agedhobbit.I'dliketolivethere.\n",
      "Number of characters (no spaces):  66\n",
      "Number of lines:  1\n"
     ]
    }
   ],
   "source": [
    "text = \"In a hole in the ground there lived a middle-aged hobbit. I'd like to live there.\"\n",
    "\n",
    "# (a) number of words\n",
    "numWords = len(normalizeRegEx(text).split())\n",
    "print(\"Number of words: \", numWords)\n",
    "\n",
    "# (b) characters (with spaces)\n",
    "numChars = len(text)\n",
    "print(\"Number of characters (with spaces): \", numChars)\n",
    "\n",
    "# (c) characters (no spaces)\n",
    "textNoSpaces = re.sub(r'[\\s]','', text)\n",
    "numCharsNoSpace = len(textNoSpaces)\n",
    "print(textNoSpaces)\n",
    "print(\"Number of characters (no spaces): \", numCharsNoSpace)\n",
    "\n",
    "# (d) lines\n",
    "numLines = 1 + text.count(\"\\n\") if len(text) > 0 else 0 # assume default of 1 line if there is content\n",
    "print(\"Number of lines: \", numLines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the Number of Paragraphs\n",
    "\n",
    "For the purposes of this project, we consider a new paragraph is started when a newline character is entered, with the option of additional white space characters before a new valid character is entered. The regex pattern for this scenario is: __r\"\\n\\s*\"__. \n",
    "\n",
    "To get the number of paragraphs, we just need to determine the number of instances this pattern is encountered in the input text. \n",
    "\n",
    "Similar to the number of lines, we follow the assumption that if the file is empty, the number of paragraphs is considered to be zero. However, if the there is at least single character in the file, even if there is no newline character (\\n), the number of paragraphs is considered to be one. \n",
    "\n",
    "To remove the effect of newline characters before and after the main body of text, the leading and trailing whitespaces removed using the __strip__ function.\n",
    "\n",
    "\n",
    "The next cells will consider several possibilities related to the extracting the number of paragraphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of paragraphs:  0\n"
     ]
    }
   ],
   "source": [
    "# Case 1: Empty text (No paragraph)\n",
    "textpar = \"\";\n",
    "\n",
    "# Get number of paragraphs\n",
    "textpar = textpar.strip()\n",
    "\n",
    "# Lets use a regular expression to match a few date strings.\n",
    "regex = r\"\\n\\s*\"\n",
    "matches = re.findall(regex, textpar)\n",
    "numParagraphs = 1 + len(matches) if len(textpar) > 0 else 0 # assume default of 1 paragraph if there is content\n",
    "print(\"Number of paragraphs: \", numParagraphs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of paragraphs:  1\n"
     ]
    }
   ],
   "source": [
    "# Case 2: Single Sentence (One paragraph)\n",
    "textpar = \"The quick brown fox jumped over the lazy dog.\";\n",
    "\n",
    "# Get number of paragraphs\n",
    "textpar = textpar.strip()\n",
    "\n",
    "# Lets use a regular expression to match a few date strings.\n",
    "regex = r\"\\n\\s*\"\n",
    "matches = re.findall(regex, textpar)\n",
    "numParagraphs = 1 + len(matches) if len(textpar) > 0 else 0 # assume default of 1 paragraph if there is content\n",
    "print(\"Number of paragraphs: \", numParagraphs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of paragraphs:  2\n"
     ]
    }
   ],
   "source": [
    "# Case 3: Two paragraphs\n",
    "textpar = \"The quick brown fox jumped over the lazy dog.\\n\\n\\t\\nThe quick brown fox jumped over the lazy dog.\";\n",
    "\n",
    "# Get number of paragraphs\n",
    "textpar = textpar.strip()\n",
    "\n",
    "# Lets use a regular expression to match a few date strings.\n",
    "regex = r\"\\n\\s*\"\n",
    "matches = re.findall(regex, textpar)\n",
    "numParagraphs = 1 + len(matches) if len(textpar) > 0 else 0 # assume default of 1 paragraph if there is content\n",
    "print(\"Number of paragraphs: \", numParagraphs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the ___PrintTextStatistics___ Function\n",
    "\n",
    "The code snippets above can be combined into a single function that we can call and print all text statistics in a concise manner. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def PrintTextStatistics(filename):\n",
    "    \"\"\" Print text statistics for a given text file \"\"\"\n",
    "    \n",
    "    with open(filename, 'r') as myfile:\n",
    "        text = myfile.read()\n",
    "    \n",
    "    # (a) number of words\n",
    "    numWords = len(normalizeRegEx(text).split())\n",
    "\n",
    "    # (b) characters (with spaces)\n",
    "    numChars = len(text)\n",
    "\n",
    "    # (c) characters (no spaces)\n",
    "    textNoSpaces = re.sub(r'[\\s]','', text)\n",
    "    numCharsNoSpaces = len(textNoSpaces)\n",
    "\n",
    "    # (d) lines\n",
    "    numLines = 1 + text.count(\"\\n\") if len(text) > 0 else 0 # assume default of 1 line if there is content\n",
    "    \n",
    "    text = text.strip() # remove leading/trailing spaces\n",
    "    \n",
    "    # (e) paragraphs\n",
    "    regex = r\"\\n\\s*\\n*\"\n",
    "    matches = re.findall(regex, text)\n",
    "    numParagraphs = 1 + len(matches) if len(text) > 0 else 0 # assume default of 1 paragraph if there is content\n",
    "    \n",
    "    # (f) print text statistics\n",
    "    print(\"Text statistics for file: \", filename)\n",
    "    print(\"Number of words: \", numWords)\n",
    "    print(\"Number of characters (with spaces): \", numChars)\n",
    "    print(\"Number of characters (no spaces): \", numCharsNoSpaces)\n",
    "    print(\"Number of lines: \", numLines)\n",
    "    print(\"Number of paragraphs: \", numParagraphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new __PrintTextStatistics__ function will be tested on a real-world text file of *The Complete Works of William Shakespeare*, available through Project Gutenberg (http://www.gutenberg.org)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text statistics for file:  data/shakespeare.txt\n",
      "Number of words:  900068\n",
      "Number of characters (with spaces):  5458199\n",
      "Number of characters (no spaces):  4039809\n",
      "Number of lines:  124457\n",
      "Number of paragraphs:  114840\n"
     ]
    }
   ],
   "source": [
    "PrintTextStatistics(\"data/shakespeare.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison purposes, the results from the Word Count box in Microsoft Word are shown below.\n",
    "\n",
    "![](figures/TextStatisticsFromShakespeare.png)\n",
    "\n",
    "The number of characters (with no spaces) and the number of paragraphs match. The other numbers are slightly off. The results from Notepad++ are also shown below.\n",
    "\n",
    "![](figures/TextStatisticsFromShakespeareNotepadPlusPlus.png)\n",
    "\n",
    "This time, the number of characters (with spaces) and the number of lines match.\n",
    "\n",
    "To explain the similarity and minor difference in numbers, this project shares the same definition of lines and characters (with spaces) with Notepad++. In terms of the number of paragraphs and characters (with no spaces), this project agrees with the definition from Microsoft Word. As for the definition of words, Microsoft Word may have an alternative approach on distinct word construction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Frequency\n",
    "\n",
    "It would also be interesting to know what are the most frequently occurring words in the given text file. The general idea is to find the distinct words and count how much they occur in the text. The counts will then be sorted in a descending order, yielding the words that occur most frequently in the text.\n",
    "\n",
    "The distinct words and the related counts will be stored in a dictionary structure, with the word as the key and counts as the value.\n",
    "\n",
    "The __GetWordFrequencyDictionary__ function (which calls __normalizeRegEx__) below can be used to get this dictionary structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def normalizeRegEx(s):\n",
    "    \"\"\"Convert string to lowercase and keep only characters \n",
    "        specified in regex pattern\"\"\"\n",
    "    return re.sub(r'[^a-z\\s\\'-]','',s.strip().lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get word frequency\n",
    "def GetWordFrequencyDictionary(text):\n",
    "    \"\"\" Returns a dictionary where the keys are distinct words and the value are the counts of those words \"\"\"\n",
    "    \n",
    "    text = normalizeRegEx(text)\n",
    "    words = text.split()\n",
    "    \n",
    "    wordFrequency = {} # Initialize dictionary\n",
    "    for word in words:\n",
    "        if word in wordFrequency: # just increment count if word was discovered before\n",
    "            wordFrequency[word] += 1\n",
    "        else:\n",
    "            wordFrequency[word] = 1 # add to dictionary\n",
    "            \n",
    "    return wordFrequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enhanced *PrintTextStatisticsWithTopWords* Function\n",
    "\n",
    "The original *PrintTextStatistics* function above will be modified to include printing the top 10 frequently occuring words in the text file. \n",
    "\n",
    "To find the number of characters (with no spaces) in the original *PrintTextStatistics* function, the __len__ function is applied to a new string variable (*textNoSpaces*) is generated from the original input text. The new implementation below uses regular expression to find all non-space characters and outputs the total number of matches as the number of characters (with no spaces)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def PrintTextStatisticsWithTopWords(filename):\n",
    "    \"\"\" Print text statistics for a given text file including most frequently occurring words \"\"\"\n",
    "        \n",
    "    with open(filename, 'r') as myfile:\n",
    "        text = myfile.read()\n",
    "        \n",
    "    # characters (with spaces)\n",
    "    numChars = len(text)\n",
    "    \n",
    "    # characters (with no spaces)\n",
    "    matchNonSpace = re.findall(r'[^\\s]', text)\n",
    "    numCharsNoSpace = len(matchNonSpace)\n",
    "        \n",
    "    # lines\n",
    "    numLines = 1 + text.count(\"\\n\") if len(text) > 0 else 0 # assume default of 1 line if there is content\n",
    "    \n",
    "    text = text.strip() # remove leading/trailing spaces for counting paragraphs\n",
    "    \n",
    "    # paragraphs\n",
    "    regex = r\"\\n\\s*\\n*\"\n",
    "    matchesPar = re.findall(regex, text)\n",
    "    numParagraphs = 1 + len(matchesPar) if len(text) > 0 else 0 # assume default of 1 paragraph if there is content\n",
    "    \n",
    "    wordFrequency = GetWordFrequencyDictionary(text)\n",
    "    \n",
    "    # number of words\n",
    "    numWords = int( np.sum([wordFrequency[word] for word in  wordFrequency]) )\n",
    "    \n",
    "    # create list of (count, word) from the dictionary\n",
    "    wordList = [(wordFrequency[word], word) for word in wordFrequency]\n",
    "    wordList.sort(reverse=True)\n",
    "    \n",
    "    # print text statistics\n",
    "    print(\"Text statistics for file: \", filename)\n",
    "    print(\"Number of words: \", numWords)\n",
    "    print(\"Number of characters (with spaces): \", numChars)\n",
    "    print(\"Number of characters (no spaces): \", numCharsNoSpace)\n",
    "    print(\"Number of lines: \", numLines)\n",
    "    print(\"Number of paragraphs: \", numParagraphs)\n",
    "    print(\"\\nThe top 10 words in the file are: \")\n",
    "    i = 1\n",
    "    for count, word in wordList[:10]:\n",
    "        print(\"{0:2d}. {1:10} {2:4d}\".format(i, word, count))\n",
    "        i+=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text statistics for file:  data/shakespeare.txt\n",
      "Number of words:  900068\n",
      "Number of characters (with spaces):  5458199\n",
      "Number of characters (no spaces):  4039809\n",
      "Number of lines:  124457\n",
      "Number of paragraphs:  114840\n",
      "\n",
      "The top 10 words in the file are: \n",
      " 1. the        27594\n",
      " 2. and        26704\n",
      " 3. i          20248\n",
      " 4. to         19165\n",
      " 5. of         18164\n",
      " 6. a          14430\n",
      " 7. you        13568\n",
      " 8. my         12461\n",
      " 9. that       11098\n",
      "10. in         10953\n"
     ]
    }
   ],
   "source": [
    "PrintTextStatisticsWithTopWords(\"data/shakespeare.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the top 10 words from the real-world text file of The Complete Works of William Shakespeare (available at http://www.gutenberg.org) are in the list of the most common words in English (https://en.wikipedia.org/wiki/Most_common_words_in_English). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acknowledgements\n",
    "\n",
    "This project was inspired by the \"*Case Study: Text Statistics*\" chapter from the book, *Python: Visual QuickStart Guide (3rd Edition)*. \n",
    "\n",
    "This project improved upon the book approach by using regular expressions to find patterns from the input text. Additional text statistics values such as the number of paragraphs and number of characters (no spaces) are also provided. \n",
    "\n",
    "The results from this project are also compared to existing third-party software that provide similar text statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
